\chapter{Mobility Markov Chain}
	The transitions in this mobility model have Markovian property in the sense that the next waypoint depends entirely on the current position. 
\begin{equation*}
	f_{X_n/X_{n-1},X_{n-2},\ldots,X_0}(x_n/x_{n-1},x_{n-2},\ldots,x_{0}) = f_{X_n/X_{n-1}}(x_n/x_{n-1})
\end{equation*}
Where $X_{n-1}$ is the current waypoint and $X_n$ is the next waypoint. \\
	The idea is to discretize the state space of this Markov chain and model the motion as an Absorbing Markov Chain in which the node transitions among the non-absorbing states present inside the region before finally moving to the absorbing state. 
Let the whole space be represented by $n+1$ states of which $n$ states lie inside the region of interest and the $n+1$th state represents the space outside the region. The transition probabilities among first $n$ states depend on the distances between the nodes and the transition probabilities from these $n$ to the absorbing state is $\rho(r_i,\theta_i)$ where $(r_i,\theta_i)$ is the position of the $i$th state. We can then use the expressions given in \cite{wiki:markovWiki}
to find expected value and variance of the number of transitions a node makes before getting absorbed in the $(n+1)$th state. The transition probability matrix of this Markov Chain is  
\begin{equation*}
	P  = \left(
	\begin{array}{cc}
	Q & R \\
		\mathbf{0} & 1 \\
	\end{array} \right)
\end{equation*}
	Where $Q_{n \times n}$ is the transition probability matrix of $n$ non-absorbing states and $R_{n\times1}$ contains the probabilities of moving out in one step from each of those $n$ states. 
	 $\mathbf{t}_{n \times 1}$, the vector which contains expected number of transitions, is given by
\begin{equation*}
	\mathbf{t} = A\mathbf{1} \\
\end{equation*}
and the variance vector $V$ is given by
\begin{equation*}
	 V = (2A-I)\mathbf{t} - \mathbf{t}_{sq}
\end{equation*}
where $A = \sum_{k=0}^{\infty} Q^k = (I-Q)^{-1}$ is the fundamental matrix.

	It remains to be seen how well this model works.
